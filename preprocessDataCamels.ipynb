{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import config\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE DIRECTORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DIR = config.RAW_DIR\n",
    "PREPROCESSED_DIR = config.PREPROCESSED_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA & REMOVE LEAP YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16436,) (671, 16425, 26) Original data\n",
      "516     1972-02-29\n",
      "1977    1976-02-29\n",
      "3438    1980-02-29\n",
      "4899    1984-02-29\n",
      "6360    1988-02-29\n",
      "7821    1992-02-29\n",
      "9282    1996-02-29\n",
      "10743   2000-02-29\n",
      "12204   2004-02-29\n",
      "13665   2008-02-29\n",
      "15126   2012-02-29\n",
      "Name: 0, dtype: datetime64[ns]\n",
      "(16425,) (671, 16414, 26) Leap year removed data\n"
     ]
    }
   ],
   "source": [
    "data = np.load(os.path.join(RAW_DIR, \"data.npy\")).astype(np.float32)\n",
    "data[data==config.unknown] = np.nan\n",
    "date = np.load(os.path.join(RAW_DIR, \"dates.npy\"), allow_pickle=True)\n",
    "print(date.shape, data.shape, \"Original data\")\n",
    "\n",
    "date_df = pd.DataFrame(date)\n",
    "date_df = pd.to_datetime(date_df[0], errors='coerce')\n",
    "print(date_df.loc[date_df.dt.month == 2].loc[date_df.dt.day == 29])\n",
    "date = np.delete(date, date_df.loc[date_df.dt.month == 2].loc[date_df.dt.day == 29].index.values)\n",
    "data = np.delete(data, date_df.loc[date_df.dt.month == 2].loc[date_df.dt.day == 29].index.values, axis=1)\n",
    "print(date.shape, data.shape, \"Leap year removed data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CREATE TRAIN AND TEST BASINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7300,) (671, 7300, 26)\n"
     ]
    }
   ],
   "source": [
    "total_date = date[np.where(date==pd.Timestamp(config.test_year[\"start\"], 10, 1, 0))[0][0]:np.where(date==pd.Timestamp(config.train_year[\"end\"], 10, 1, 0))[0][0]]\n",
    "total_data = data[:,np.where(date==pd.Timestamp(config.test_year[\"start\"], 10, 1, 0))[0][0]:np.where(date==pd.Timestamp(config.train_year[\"end\"], 10, 1, 0))[0][0]]\n",
    "print(total_date.shape, total_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376 282 94\n",
      "Total\tMin Mean SF:0.1849\tNode:264\tMin Median SF:0.0000\tNode:358\n",
      "Total\tMax Mean SF:8.1869\tNode:658\tMax Median SF:5.2050\tNode:33\n",
      "Train\tMin Mean SF:0.2108\tNode:168\tMin Median SF:0.0000\tNode:358\n",
      "Train\tMax Mean SF:8.1869\tNode:658\tMax Median SF:5.2050\tNode:33\n",
      "Test\tMin Mean SF:0.1849\tNode:264\tMin Median SF:0.0700\tNode:206\n",
      "Test\tMax Mean SF:6.9310\tNode:610\tMax Median SF:4.0700\tNode:336\n"
     ]
    }
   ],
   "source": [
    "node_flow = np.zeros((len(total_data), 2))\n",
    "for node in range(len(total_data)):\n",
    "\tnode_labels = total_data[node, :, config.output_channels]\n",
    "\tmean = np.mean(node_labels)\n",
    "\tmedian = np.median(node_labels)\n",
    "\tnode_flow[node,0] = mean\n",
    "\tnode_flow[node,1] = median\n",
    "indices = np.argsort(node_flow[:,0])\n",
    "mask = np.ones(len(node_flow)).astype(bool)\n",
    "mask[::4] = 0\n",
    "nan_indices = np.where(np.isnan(node_flow[:,0]))[0]\n",
    "total_indices = np.array([index for index in indices if index not in nan_indices])\n",
    "train_indices = np.array([index for index in indices[mask] if index not in nan_indices])\n",
    "test_indices = np.array([index for index in indices[~mask] if index not in nan_indices])\n",
    "print(len(total_indices), len(train_indices), len(test_indices))\n",
    "\n",
    "total_node_flow = node_flow[total_indices]\n",
    "print(\"Total\\tMin Mean SF:{:.4f}\\tNode:{}\\tMin Median SF:{:.4f}\\tNode:{}\".format(np.min(total_node_flow[:,0]), total_indices[np.argmin(total_node_flow[:,0])], np.min(total_node_flow[:,1]), total_indices[np.argmin(total_node_flow[:,1])]))\n",
    "print(\"Total\\tMax Mean SF:{:.4f}\\tNode:{}\\tMax Median SF:{:.4f}\\tNode:{}\".format(np.max(total_node_flow[:,0]), total_indices[np.argmax(total_node_flow[:,0])], np.max(total_node_flow[:,1]), total_indices[np.argmax(total_node_flow[:,1])]))\n",
    "\n",
    "train_node_flow = node_flow[train_indices]\n",
    "print(\"Train\\tMin Mean SF:{:.4f}\\tNode:{}\\tMin Median SF:{:.4f}\\tNode:{}\".format(np.min(train_node_flow[:,0]), train_indices[np.argmin(train_node_flow[:,0])], np.min(train_node_flow[:,1]), train_indices[np.argmin(train_node_flow[:,1])]))\n",
    "print(\"Train\\tMax Mean SF:{:.4f}\\tNode:{}\\tMax Median SF:{:.4f}\\tNode:{}\".format(np.max(train_node_flow[:,0]), train_indices[np.argmax(train_node_flow[:,0])], np.max(train_node_flow[:,1]), train_indices[np.argmax(train_node_flow[:,1])]))\n",
    "\n",
    "test_node_flow = node_flow[test_indices]\n",
    "print(\"Test\\tMin Mean SF:{:.4f}\\tNode:{}\\tMin Median SF:{:.4f}\\tNode:{}\".format(np.min(test_node_flow[:,0]), test_indices[np.argmin(test_node_flow[:,0])], np.min(test_node_flow[:,1]), test_indices[np.argmin(test_node_flow[:,1])]))\n",
    "print(\"Test\\tMax Mean SF:{:.4f}\\tNode:{}\\tMax Median SF:{:.4f}\\tNode:{}\".format(np.max(test_node_flow[:,0]), test_indices[np.argmax(test_node_flow[:,0])], np.max(test_node_flow[:,1]), test_indices[np.argmax(test_node_flow[:,1])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(total_node_flow.shape[0]//4, total_node_flow.shape[0]//8))\n",
    "# fontsize = 10\n",
    "# width = 0.4\n",
    "# ax = fig.add_subplot(111)\n",
    "# ax.set_xticks(range(len(total_node_flow[:,0])))\n",
    "# ax.set_xticklabels(total_indices, fontsize=fontsize, rotation=90)\n",
    "# ax.bar(np.array(range(len(total_node_flow))), total_node_flow[:,0], width=width , color=\"Green\", label = \"Mean\")\n",
    "# ax.bar(np.array(range(len(total_node_flow))), total_node_flow[:,1], width=width , color=\"Blue\", label = \"Median\")\n",
    "# ax.legend(loc=\"upper left\")\n",
    "# plt.show()\n",
    "\n",
    "# fig = plt.figure(figsize=(train_node_flow.shape[0]//4, train_node_flow.shape[0]//8))\n",
    "# fontsize = 10\n",
    "# width = 0.4\n",
    "# ax = fig.add_subplot(111)\n",
    "# ax.set_xticks(range(len(train_node_flow[:,0])))\n",
    "# ax.set_xticklabels(train_indices, fontsize=fontsize, rotation=90)\n",
    "# ax.bar(np.array(range(len(train_node_flow))), train_node_flow[:,0], width=width , color=\"Green\", label = \"Mean\")\n",
    "# ax.bar(np.array(range(len(train_node_flow))), train_node_flow[:,1], width=width , color=\"Blue\", label = \"Median\")\n",
    "# ax.legend(loc=\"upper left\")\n",
    "# plt.show()\n",
    "\n",
    "# fig = plt.figure(figsize=(test_node_flow.shape[0]//4, test_node_flow.shape[0]//8))\n",
    "# fontsize = 10\n",
    "# width = 0.4\n",
    "# ax = fig.add_subplot(111)\n",
    "# ax.set_xticks(range(len(test_node_flow[:,0])))\n",
    "# ax.set_xticklabels(test_indices, fontsize=fontsize, rotation=90)\n",
    "# ax.bar(np.array(range(len(test_node_flow))), test_node_flow[:,0], width=width , color=\"Green\", label = \"Mean\")\n",
    "# ax.bar(np.array(range(len(test_node_flow))), test_node_flow[:,1], width=width , color=\"Blue\", label = \"Median\")\n",
    "# ax.legend(loc=\"upper left\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE TRAIN & TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3650,) (671, 3650, 26)\n",
      "(730,) (671, 730, 26)\n",
      "(2920,) (671, 2920, 26)\n"
     ]
    }
   ],
   "source": [
    "train_date = date[np.where(date==pd.Timestamp(config.train_year[\"start\"], 10, 1, 0))[0][0]:np.where(date==pd.Timestamp(config.train_year[\"end\"], 10, 1, 0))[0][0]]\n",
    "train_data = data[:,np.where(date==pd.Timestamp(config.train_year[\"start\"], 10, 1, 0))[0][0]:np.where(date==pd.Timestamp(config.train_year[\"end\"], 10, 1, 0))[0][0]]\n",
    "print(train_date.shape, train_data.shape)\n",
    "\n",
    "valid_date = date[np.where(date==pd.Timestamp(config.valid_year[\"start\"], 10, 1, 0))[0][0]:np.where(date==pd.Timestamp(config.valid_year[\"end\"], 10, 1, 0))[0][0]]\n",
    "valid_data = data[:,np.where(date==pd.Timestamp(config.valid_year[\"start\"], 10, 1, 0))[0][0]:np.where(date==pd.Timestamp(config.valid_year[\"end\"], 10, 1, 0))[0][0]]\n",
    "print(valid_date.shape, valid_data.shape)\n",
    "\n",
    "test_date = date[np.where(date==pd.Timestamp(config.test_year[\"start\"], 10, 1, 0))[0][0]:np.where(date==pd.Timestamp(config.test_year[\"end\"], 10, 1, 0))[0][0]]\n",
    "test_data = data[:,np.where(date==pd.Timestamp(config.test_year[\"start\"], 10, 1, 0))[0][0]:np.where(date==pd.Timestamp(config.test_year[\"end\"], 10, 1, 0))[0][0]]\n",
    "print(test_date.shape, test_data.shape)\n",
    "\n",
    "train_data_means = np.nanmean(train_data, axis=(0,1))\n",
    "train_data_stds = np.nanstd(train_data, axis=(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE TRAIN & TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:(3650,)\tData:(671, 3650, 26)\tMeans:(26,)\tStds:(26,)\tTrain_Index:(282,)\tTest_Index:(94,)\tTrain\n",
      "Date:(730,)\tData:(671, 730, 26)\tMeans:(26,)\tStds:(26,)\tTrain_Index:(282,)\tTest_Index:(94,)\tValid\n",
      "Date:(2920,)\tData:(671, 2920, 26)\tMeans:(26,)\tStds:(26,)\tTrain_Index:(282,)\tTest_Index:(94,)\tTest\n"
     ]
    }
   ],
   "source": [
    "print(\"Date:{}\\tData:{}\\tMeans:{}\\tStds:{}\\tTrain_Index:{}\\tTest_Index:{}\\tTrain\".format(train_date.shape, train_data.shape, train_data_means.shape, train_data_stds.shape, train_indices.shape, test_indices.shape))\n",
    "np.savez(os.path.join(PREPROCESSED_DIR, \"train.npz\"), date=train_date, data=train_data, train_data_means=train_data_means, train_data_stds=train_data_stds, train_index=train_indices, test_index=test_indices)\n",
    "print(\"Date:{}\\tData:{}\\tMeans:{}\\tStds:{}\\tTrain_Index:{}\\tTest_Index:{}\\tValid\".format(valid_date.shape, valid_data.shape, train_data_means.shape, train_data_stds.shape, train_indices.shape, test_indices.shape))\n",
    "np.savez(os.path.join(PREPROCESSED_DIR, \"valid.npz\"), date=valid_date, data=valid_data, train_data_means=train_data_means, train_data_stds=train_data_stds, train_index=train_indices, test_index=test_indices)\n",
    "print(\"Date:{}\\tData:{}\\tMeans:{}\\tStds:{}\\tTrain_Index:{}\\tTest_Index:{}\\tTest\".format(test_date.shape, test_data.shape, train_data_means.shape, train_data_stds.shape, train_indices.shape, test_indices.shape))\n",
    "np.savez(os.path.join(PREPROCESSED_DIR, \"test.npz\"), date=test_date, data=test_data, train_data_means=train_data_means, train_data_stds=train_data_stds, train_index=train_indices, test_index=test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE STRIDED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createStridedData(date, data):\n",
    "\tstrided_data = np.zeros((data.shape[0], 2*(len(date)//config.window), config.window, data.shape[-1])).astype(np.float32)\n",
    "\n",
    "\ti = 0\n",
    "\tk = 0\n",
    "\twhile i<len(date):\n",
    "\t\tstrided_data[:, k] = data[:, i:i+config.window]\n",
    "\t\tk += 1\n",
    "\n",
    "\t\tif strided_data[:, k].shape == data[:, i+config.stride:i+config.stride+config.window].shape:\n",
    "\t\t\tstrided_data[:, k] = data[:, i+config.stride:i+config.stride+config.window]\n",
    "\t\t\tk += 1\n",
    "\n",
    "\t\ti = i+config.window\n",
    "\tstrided_data = strided_data[:, :k]\n",
    "\treturn strided_data\n",
    "\n",
    "strided_train_data = createStridedData(train_date, train_data)\n",
    "strided_valid_data = createStridedData(valid_date, valid_data)\n",
    "strided_test_data = createStridedData(test_date, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE STRIDED TRAIN & TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:(3650,)\tData:(671, 19, 365, 26)\tMeans:(26,)\tStds:(26,)\tTrain_Index:(282,)\tTest_Index:(94,)\tTrain\n",
      "Date:(730,)\tData:(671, 3, 365, 26)\tMeans:(26,)\tStds:(26,)\tTrain_Index:(282,)\tTest_Index:(94,)\tValid\n",
      "Date:(2920,)\tData:(671, 15, 365, 26)\tMeans:(26,)\tStds:(26,)\tTrain_Index:(282,)\tTest_Index:(94,)\tTest\n"
     ]
    }
   ],
   "source": [
    "print(\"Date:{}\\tData:{}\\tMeans:{}\\tStds:{}\\tTrain_Index:{}\\tTest_Index:{}\\tTrain\".format(train_date.shape, strided_train_data.shape, train_data_means.shape, train_data_stds.shape, train_indices.shape, test_indices.shape))\n",
    "np.savez(os.path.join(PREPROCESSED_DIR, \"strided_train.npz\"), date=train_date, data=strided_train_data, train_data_means=train_data_means, train_data_stds=train_data_stds, train_index=train_indices, test_index=test_indices)\n",
    "print(\"Date:{}\\tData:{}\\tMeans:{}\\tStds:{}\\tTrain_Index:{}\\tTest_Index:{}\\tValid\".format(valid_date.shape, strided_valid_data.shape, train_data_means.shape, train_data_stds.shape, train_indices.shape, test_indices.shape))\n",
    "np.savez(os.path.join(PREPROCESSED_DIR, \"strided_valid.npz\"), date=valid_date, data=strided_valid_data, train_data_means=train_data_means, train_data_stds=train_data_stds, train_index=train_indices, test_index=test_indices)\n",
    "print(\"Date:{}\\tData:{}\\tMeans:{}\\tStds:{}\\tTrain_Index:{}\\tTest_Index:{}\\tTest\".format(test_date.shape, strided_test_data.shape, train_data_means.shape, train_data_stds.shape, train_indices.shape, test_indices.shape))\n",
    "np.savez(os.path.join(PREPROCESSED_DIR, \"strided_test.npz\"), date=test_date, data=strided_test_data, train_data_means=train_data_means, train_data_stds=train_data_stds, train_index=train_indices, test_index=test_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
